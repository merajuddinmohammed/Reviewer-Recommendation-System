# Applied AI Assignment - PDF Paper Management System

A robust Windows-friendly system for ingesting, parsing, and managing academic papers with GPU acceleration support.

## ğŸ¯ Overview

This system provides a complete pipeline for:
- **PDF Ingestion**: Automated extraction of text and metadata from academic papers
- **Database Management**: SQLite-based storage with relationship tracking
- **Co-author Networks**: Automatic detection and analysis of collaboration patterns
- **GPU Acceleration**: CUDA 11.8 support for future ML tasks
- **Resilient Processing**: Handles corrupted PDFs without crashing

## ğŸš€ Quick Start

### 1. Clone or Setup Project

```powershell
cd "C:\Users\meraj\OneDrive\Desktop\Applied AI Assignment"
```

### 2. Run Automated Setup

```powershell
.\setup.ps1
```

This will:
- âœ… Create Python virtual environment in `backend/.venv`
- âœ… Install PyTorch with CUDA 11.8
- âœ… Install all Python dependencies
- âœ… Install Node.js dependencies
- âœ… Verify GPU availability
- âœ… Create configuration files

### 3. Test Installation

```powershell
# Activate environment
cd backend
.\.venv\Scripts\Activate.ps1

# Test database layer
python db_utils.py

# Test parser
python parser.py
```

Both should show: **ALL TESTS PASSED âœ“**

### 4. Ingest the Dataset

The dataset is already organized in the `Dataset/` folder with 70+ authors.

```powershell
# Activate environment (if not already active)
cd backend
.\.venv\Scripts\Activate.ps1

# Run ingestion (uses Dataset/ by default)
python ingest.py

# This will:
# - Process all PDFs in Dataset/
# - Create data/papers.db with metadata
# - Generate data/ingest_summary.csv with statistics
# - Build co-author network
```

**Note:** First run may take 15-30 minutes depending on dataset size. Safe to rerun - skips duplicates automatically.

## ğŸ“ Project Structure

```
Applied AI Assignment/
â”‚
â”œâ”€â”€ setup.ps1                    # Automated Windows setup script
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ README-SETUP.md              # Detailed setup guide
â”œâ”€â”€ SUMMARY.md                   # Technical summary
â”‚
â”œâ”€â”€ Dataset/                     # Academic papers dataset
â”‚   â”œâ”€â”€ Amit Saxena/            # Author folders
â”‚   â”œâ”€â”€ Amita Jain/
â”‚   â”œâ”€â”€ ... (70+ authors)
â”‚   â””â”€â”€ (PDFs organized by author)
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ .venv/                   # Python virtual environment
â”‚   â”œâ”€â”€ .env                     # Environment configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ db_utils.py             # SQLite database layer
â”‚   â”œâ”€â”€ parser.py               # PDF ingestion & parsing
â”‚   â”œâ”€â”€ utils.py                # Text cleaning utilities
â”‚   â”œâ”€â”€ tfidf_engine.py         # TF-IDF similarity search
â”‚   â”œâ”€â”€ embedding.py            # Sentence embeddings + FAISS
â”‚   â”œâ”€â”€ topic_model.py          # OPTIONAL: BERTopic topic modeling
â”‚   â”œâ”€â”€ coauthor_graph.py       # Co-author network & COI detection
â”‚   â”œâ”€â”€ ingest.py               # CLI ingestion script
â”‚   â”‚
â”‚   â”œâ”€â”€ demo_parser.py          # Parser demo script
â”‚   â”œâ”€â”€ demo_full_pipeline.py   # Full pipeline demo
â”‚   â”œâ”€â”€ test_tfidf_quick.py     # TF-IDF quick tests
â”‚   â”‚
â”‚   â”œâ”€â”€ README-PARSER.md        # Parser documentation
â”‚   â”œâ”€â”€ README-UTILS.md         # Utils documentation
â”‚   â”œâ”€â”€ README-TFIDF.md         # TF-IDF documentation
â”‚   â”œâ”€â”€ README-EMBEDDING.md     # Embeddings documentation
â”‚   â”œâ”€â”€ README-TOPIC.md         # Topic modeling documentation
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                   # Generated data
â”‚   â”‚   â”œâ”€â”€ papers.db           # SQLite database
â”‚   â”‚   â””â”€â”€ ingest_summary.csv  # Ingestion statistics
â”‚   â”‚
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ hf_cache/           # Hugging Face model cache
â”‚       â”œâ”€â”€ tfidf_latest.joblib # Trained TF-IDF model
â”‚       â”œâ”€â”€ faiss_scibert.index # FAISS semantic index
â”‚       â””â”€â”€ bertopic_model/     # BERTopic models (optional)
â”‚
â””â”€â”€ frontend/
    â””â”€â”€ (Future: React/Next.js UI)
```

## ğŸ“¦ Components

### 1. Environment Setup (`setup.ps1`)

**Features:**
- Idempotent setup script (safe to re-run)
- Python 3.10+ validation
- PyTorch CUDA 11.8 installation
- All dependencies with pinned versions
- GPU verification with `torch.cuda.is_available()`
- Environment file creation

**Usage:**
```powershell
.\setup.ps1                    # Full setup
.\setup.ps1 -SkipNode         # Skip Node.js setup
.\setup.ps1 -Force            # Force recreate venv
```

**Documentation:** See `README-SETUP.md`

### 2. Database Layer (`backend/db_utils.py`)

**Features:**
- SQLite with WAL mode for concurrency
- 5-table schema for papers, authors, and relationships
- MD5-based duplicate prevention
- Upsert operations for safe updates
- Co-author network builder
- Comprehensive query helpers

**Schema:**
```sql
authors          (id, name, affiliation)
papers           (id, author_id, title, year, abstract, fulltext, md5)
paper_authors    (paper_id, person_name, author_order)
coauthors        (author_id, coauthor_name, collaboration_count)
paper_vectors    (paper_id, dim, norm, faiss_index)
```

**Usage:**
```python
import db_utils

# Initialize
db_utils.init_db("papers.db")

# Add author
author_id = db_utils.upsert_author("papers.db", "Alice Smith", "MIT")

# Add paper
paper_id, is_new = db_utils.upsert_paper(
    "papers.db",
    author_id=author_id,
    title="Deep Learning Fundamentals",
    md5="abc123",
    year=2023
)

# Query
papers = db_utils.get_all_papers("papers.db")
```

### 3. PDF Parser (`backend/parser.py`)

**Features:**
- Multi-library fallback (pdfplumber â†’ PyPDF2 â†’ Tika)
- Smart title extraction (metadata â†’ heuristics â†’ filename)
- Year detection (metadata + regex patterns)
- Abstract extraction (pattern-based)
- Author parsing with delimiter splitting
- MD5 deduplication
- Resilient error handling (one bad PDF won't crash)
- Detailed statistics reporting

**Usage:**
```python
from pathlib import Path
from parser import walk_and_ingest

# Directory structure: papers/Author Name/*.pdf
results = walk_and_ingest(
    root_dir=Path("papers"),
    db_path=Path("papers.db")
)

print(f"Processed: {results['successful_pdfs']}/{results['total_pdfs']}")
print(f"Abstracts: {results['abstract_percentage']:.1f}%")
print(f"Years: {results['year_percentage']:.1f}%")
```

**Documentation:** See `backend/README-PARSER.md`

### 4. Text Utilities (`backend/utils.py`)

**Features:**
- Text cleaning and normalization
- Abstract/fulltext splitting (300-1500 word heuristic)
- Recency weighting (exponential decay)
- Device detection (CUDA/CPU)
- Year validation and normalization
- Text truncation utilities
- Pure functions (no side effects)
- Safe imports (works without PyTorch)

**Usage:**
```python
from utils import clean_text, split_abstract_fulltext, recency_weight, device

# Clean text
text = clean_text("  HELLO   WORLD  ")  # â†’ "hello world"

# Split text
paper = {"fulltext": "..." * 1000}
abstract, fulltext = split_abstract_fulltext(paper)

# Calculate recency weight
weight = recency_weight(2020, 2023, tau=3.0)  # â†’ 0.368

# Check device
dev = device()  # â†’ "cuda" or "cpu"
```

**Documentation:** See `backend/README-UTILS.md`

### 5. TF-IDF Similarity Engine (`backend/tfidf_engine.py`)

**Features:**
- Sparse TF-IDF vectorization with sklearn
- Fast cosine similarity search (<1ms for 1000 docs)
- Configurable n-grams and document frequency filters
- Paper ID tracking for result retrieval
- Model persistence with joblib
- Top terms extraction per document
- Memory-efficient sparse matrices (CSR format)

**Usage:**
```python
from tfidf_engine import TFIDFEngine

# Initialize and fit
engine = TFIDFEngine(
    max_features=50000,
    ngram_range=(1, 2),
    min_df=2,
    max_df=0.85
)

engine.fit(corpus_texts, paper_ids)

# Search for similar papers
results = engine.most_similar("deep learning", topn=10)
for paper_id, score in results:
    print(f"Paper {paper_id}: {score:.4f}")

# Save model
engine.save("models/tfidf_latest.joblib")

# Load later
engine = TFIDFEngine.load("models/tfidf_latest.joblib")
```

**Documentation:** See `backend/README-TFIDF.md`

### 6. Sentence Embeddings + FAISS (`backend/embedding.py`)

**Features:**
- SciBERT/SPECTER models for scientific papers
- GPU acceleration with automatic device detection
- Batched encoding with progress bars
- Mean pooling and float32 output
- L2 normalization for cosine similarity
- FAISS IndexFlatIP for fast search
- Index persistence with ID mapping
- NaN handling for robust encoding

**Usage:**
```python
from embedding import Embeddings, build_faiss_index, save_index, search_index

# Initialize with SciBERT
emb = Embeddings(model_name="allenai/scibert_scivocab_uncased")

# Encode texts
texts = ["deep learning", "neural networks", "transformers"]
vectors = emb.encode_texts(texts, normalize=True)

# Build FAISS index
index = build_faiss_index(vectors, dim=emb.dim, metric="ip")

# Save with ID mapping
save_index(index, "models/faiss_scibert", paper_ids=[101, 102, 103])

# Load and search
from embedding import load_index
index, id_map = load_index("models/faiss_scibert")
query_vec = emb.encode_texts(["attention mechanisms"], normalize=True)
scores, paper_ids = search_index(index, query_vec, k=10, id_map=id_map)

print(f"Top-10 similar papers: {paper_ids[0]}")
print(f"Similarity scores: {scores[0]}")
```

**Supported Models:**
- `allenai/scibert_scivocab_uncased` - 768 dim, scientific papers (recommended)
- `allenai/specter` - 768 dim, paper-level embeddings (recommended)
- `sentence-transformers/all-MiniLM-L6-v2` - 384 dim, fast general purpose

**Performance:**
- Encoding: ~20 docs/sec (CPU), ~200 docs/sec (GPU)
- Search: 0.5-20ms for 1K-100K documents
- Memory: 3MB per 1K papers (768 dim embeddings)

**Documentation:** See `backend/README-EMBEDDING.md`

### 7. Topic Modeling with BERTopic (`backend/topic_model.py`) - OPTIONAL

âš ï¸ **This module is OPTIONAL and the system works perfectly without it.**

**Features:**
- BERTopic for topic discovery in paper abstracts
- UMAP dimensionality reduction + HDBSCAN clustering
- Author expertise profiling by topics
- Topic overlap scoring (cosine/Jaccard)
- Graceful degradation when dependencies unavailable
- All functions return None if packages not installed

**Usage:**
```python
from topic_model import is_available, train_bertopic, author_topic_profile

# Check if topic modeling available
if is_available():
    # Train on abstracts
    model = train_bertopic(abstracts, min_topic_size=10)
    
    # Get author's expertise
    topics = author_topic_profile(author_id=42, db_path="papers.db")
    if topics:
        for topic_id, topic_name, weight in topics:
            print(f"{topic_name}: {weight:.2f}")
else:
    print("Topic modeling not available - continuing without it")
```

**Installation (Optional):**
```powershell
# Requires C++ Build Tools on Windows
pip install bertopic umap-learn hdbscan
```

**Note:** If installation fails (common on Windows due to C++ compiler requirement), the system will work without topic modeling. Use TF-IDF and embeddings for search instead.

**When to Use:**
- âœ… You have 50+ papers with abstracts
- âœ… You want to discover research themes
- âœ… You need author expertise profiles
- âŒ Skip if installation fails (not required)

**Documentation:** See `backend/README-TOPIC.md`

## ğŸ”§ Requirements

### System Requirements
- **OS**: Windows 10/11
- **Python**: 3.10+
- **Node.js**: 20 LTS (optional, for frontend)
- **GPU**: NVIDIA GPU with CUDA 11.8 support (recommended)
- **RAM**: 8GB minimum, 16GB recommended
- **Disk**: 5GB for dependencies + space for PDFs + models

### NVIDIA GPU Setup
1. Install NVIDIA drivers from: https://www.nvidia.com/Download/index.aspx
2. Verify with: `nvidia-smi`
3. CUDA toolkit 11.8 (optional, PyTorch includes CUDA libraries)

## ğŸ“š Python Dependencies

### Core Framework
- `fastapi==0.104.1` - Modern async web framework
- `uvicorn[standard]==0.24.0` - ASGI server
- `pydantic==2.5.0` - Data validation

### Data Science
- `numpy==1.24.3` - Numerical computing
- `pandas==2.0.3` - Data manipulation
- `scikit-learn==1.3.2` - Machine learning
- `scipy==1.11.4` - Scientific computing

### Machine Learning
- `torch`, `torchvision`, `torchaudio` - PyTorch with CUDA 11.8
- `lightgbm==4.1.0` - LambdaRank (CPU)
- `sentence-transformers==2.2.2` - Semantic embeddings
- `transformers==4.35.2` - Hugging Face transformers
- `faiss-cpu==1.7.4` - Fast similarity search

### PDF Processing
- `pdfplumber==0.10.3` - PDF text extraction (primary)
- `pypdf2==3.0.1` - PDF manipulation (fallback)
- `tika==2.6.0` - Apache Tika wrapper (last resort)

### Topic Modeling
- `bertopic==0.15.0` - Topic modeling
- `umap-learn==0.5.5` - Dimensionality reduction
- `hdbscan==0.8.33` - Clustering

## ğŸ§ª Testing

### Database Tests
```powershell
cd backend
python db_utils.py
```

**Tests:**
- âœ… Database initialization
- âœ… Author upsert with duplicates
- âœ… Paper upsert with MD5 deduplication
- âœ… Co-author relationship building
- âœ… Query operations
- âœ… Data integrity validation

### Parser Tests
```powershell
cd backend
python parser.py
```

**Tests:**
- âœ… MD5 computation
- âœ… Title extraction (metadata + heuristics)
- âœ… Year detection (multiple patterns)
- âœ… Abstract extraction
- âœ… Author name parsing
- âœ… Filename fallback
- âœ… Resilience to empty data

## ğŸ“– Usage Examples

### Example 1: Basic Setup and Ingestion

```powershell
# 1. Run setup
.\setup.ps1

# 2. Organize PDFs
# papers/
#   Alice Smith/
#     paper1.pdf
#     paper2.pdf
#   Bob Johnson/
#     paper3.pdf

# 3. Activate environment
cd backend
.\.venv\Scripts\Activate.ps1

# 4. Run ingestion
python -c "from parser import walk_and_ingest; from pathlib import Path; results = walk_and_ingest(Path('../papers'), Path('papers.db')); print(results)"
```

### Example 2: Query Database

```python
from backend import db_utils

# List all authors
authors = db_utils.list_authors("papers.db")
for author in authors:
    print(f"{author['name']}: {author['paper_count']} papers")

# Get papers by author
alice = db_utils.find_author_by_name("papers.db", "Alice Smith")
if alice:
    papers = db_utils.get_author_papers("papers.db", alice['id'])
    for paper in papers:
        print(f"{paper['year']}: {paper['title']}")

# Get co-authors
coauthors = db_utils.get_coauthors("papers.db", alice['id'])
for coauthor in coauthors:
    print(f"{coauthor['coauthor_name']}: {coauthor['collaboration_count']} collaborations")
```

### Example 3: Custom PDF Processing

```python
from pathlib import Path
from backend.parser import (
    extract_text_with_fallback,
    extract_title,
    extract_year,
    extract_abstract,
    parse_author_names
)

# Process single PDF
pdf_path = Path("paper.pdf")

# Extract
text, metadata = extract_text_with_fallback(pdf_path)

# Parse
title = extract_title(text, pdf_path.name, metadata)
year = extract_year(text, metadata)
abstract = extract_abstract(text)
authors = parse_author_names(text, metadata)

print(f"Title: {title}")
print(f"Year: {year}")
print(f"Authors: {', '.join(authors)}")
print(f"Abstract: {abstract[:100]}...")
```

## ğŸ› Troubleshooting

### Issue: `torch.cuda.is_available()` returns False

**Solutions:**
1. Check NVIDIA drivers: `nvidia-smi`
2. Reinstall PyTorch with CUDA:
   ```powershell
   pip uninstall torch torchvision torchaudio
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```
3. Verify GPU compatibility with CUDA 11.8

### Issue: PDF extraction fails

**Solutions:**
1. Check if all PDF libraries are installed: `pip list | Select-String pdf`
2. Try different extraction method manually
3. Check if PDF is encrypted or scanned image
4. Use OCR for scanned PDFs (tesseract)

### Issue: Setup script fails

**Solutions:**
1. Run PowerShell as Administrator
2. Enable script execution:
   ```powershell
   Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
   ```
3. Check Python version: `python --version` (must be 3.10+)
4. Use manual setup steps from `README-SETUP.md`

### Issue: Database locked error

**Solutions:**
1. Close all connections to database
2. WAL mode should prevent most locks
3. Check if another process is using the DB
4. Restart and try again

## ğŸ“Š Performance

### Benchmarks (typical hardware)

| Operation | Time | Notes |
|-----------|------|-------|
| Setup (first run) | ~5-10 min | Downloads PyTorch + deps |
| Setup (cached) | ~2 min | Packages cached |
| DB initialization | <1s | Creates empty schema |
| PDF ingestion | ~0.5-2s/PDF | Depends on PDF size |
| Query operations | <100ms | With proper indexes |

### Optimization Tips

1. **Pre-organize PDFs**: Use author-based folders from start
2. **Batch processing**: Process 100-1000 PDFs at once
3. **SSD storage**: Faster I/O for database and PDFs
4. **Skip full text**: Set `fulltext=None` if not needed for ML

## ğŸ”œ Next Steps

### Completed Features âœ…

1. âœ… **Vector Embeddings** - sentence-transformers with SciBERT/SPECTER
2. âœ… **FAISS Indexing** - Fast similarity search with GPU acceleration
3. âœ… **Topic Modeling** - BERTopic (optional module)
4. âœ… **TF-IDF Search** - Sparse keyword similarity

### Planned Features

1. **LambdaRank**
   - Personalized ranking with LightGBM
   - Training on user preferences

2. **REST API**
   - FastAPI endpoints
   - Search, recommendation, ranking

3. **Frontend UI**
   - React/Next.js interface
   - Paper browser and search

4. **Citation Analysis**
   - Citation network visualization
   - Influence metrics

### Implementation Priority

1. âœ… Environment setup
2. âœ… Database layer
3. âœ… PDF ingestion
4. âœ… Text utilities
5. âœ… TF-IDF similarity engine
6. âœ… Vector embeddings (SciBERT/SPECTER)
7. âœ… FAISS indexing
8. âœ… Topic modeling (BERTopic - optional)
9. ğŸ”„ LambdaRank trainer (next)
10. ğŸ”„ FastAPI backend
11. ğŸ”„ Frontend UI

## ğŸ“ Documentation

- **Main README**: `README.md` (this file)
- **Setup Guide**: `README-SETUP.md` - Detailed Windows setup
- **Parser Guide**: `backend/README-PARSER.md` - PDF ingestion details
- **Utils Guide**: `backend/README-UTILS.md` - Text utilities
- **TF-IDF Guide**: `backend/README-TFIDF.md` - Keyword similarity
- **Embeddings Guide**: `backend/README-EMBEDDING.md` - Semantic search
- **Topic Guide**: `backend/README-TOPIC.md` - Topic modeling (optional)
- **Technical Summary**: `SUMMARY.md` - Implementation details
- **Completion Reports**: `PROMPT6_COMPLETION.md`, `PROMPT7_COMPLETION.md`
- **Final Status**: `FINAL_PROJECT_STATUS.md` - Complete system overview
- **Inline Docs**: Comprehensive docstrings in all Python files

## ğŸ¤ Contributing

### Code Style
- Use type hints
- Add docstrings for all functions
- Follow PEP 8 conventions
- Add unit tests for new features

### Testing
```powershell
# Run all tests
cd backend
python db_utils.py
python parser.py
```

### Git Workflow
```powershell
git add .
git commit -m "Description of changes"
git push
```

## ğŸ“„ License

[Add your license here]

## ğŸ‘¥ Authors

- **Meraj** - Initial implementation

## ğŸ™ Acknowledgments

- PyTorch team for CUDA support
- Hugging Face for transformers
- FastAPI team for the framework
- Open source PDF parsing libraries

---

**Version**: 1.0.0  
**Status**: Phase 1 Complete (Setup + Database + Parser + Utils + TF-IDF + Embeddings + Topics)  
**Prompts Completed**: 7 of 7 âœ…  
**Last Updated**: December 2024  
**Python**: 3.10+  
**GPU**: CUDA 11.8

---

## ğŸ†˜ Support

If you encounter issues:

1. Check the troubleshooting sections in:
   - `README-SETUP.md` - Setup issues
   - `backend/README-PARSER.md` - Parser issues
   - This file - General issues

2. Run tests to identify the problem:
   ```powershell
   python backend/db_utils.py
   python backend/parser.py
   ```

3. Check logs for error messages

4. Verify all prerequisites are installed correctly

---

**Happy Paper Mining! ğŸ“šğŸš€**
