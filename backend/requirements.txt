# Railway Optimized Requirements - Fast Build
# Core Web Framework
fastapi
uvicorn[standard]
python-multipart

# Data Processing
numpy<2.0.0
pandas
scipy

# Machine Learning
scikit-learn
lightgbm
joblib
faiss-cpu

# NLP & Embeddings (lighter versions for faster install)
sentence-transformers
transformers
torch
tokenizers
huggingface-hub

# PDF Processing
pdfplumber
PyPDF2

# Data Validation
pydantic

# Utilities
tqdm

# Optional Topic Modeling (BERTopic)
# bertopic==0.16.0
# umap-learn==0.5.4
# hdbscan==0.8.33

# ============================================================================
# Development Dependencies (not needed in production)
# ============================================================================
# pytest==8.3.4
# pytest-asyncio==0.23.8
# httpx==0.27.0  # For testing FastAPI

# ============================================================================
# Notes:
# ============================================================================
# 1. For GPU support in local development:
#    - Uninstall faiss-cpu: pip uninstall faiss-cpu
#    - Install faiss-gpu: pip install faiss-gpu
#    - Ensure CUDA 11.8 is installed
#
# 2. For production (CPU-only):
#    - Use faiss-cpu (already in this list)
#    - torch will use CPU by default
#    - sentence-transformers will use CPU
#
# 3. Embeddings are prebuilt at deploy time, so GPU is not needed at runtime
#    - FAISS index: data/faiss_index.faiss
#    - TF-IDF model: models/tfidf_vectorizer.pkl
#    - LightGBM model: models/lgbm_ranker.pkl
#
# 4. For Windows + CUDA 11.8 development:
#    pip install torch==2.9.0+cu118 -f https://download.pytorch.org/whl/torch_stable.html
#
# 5. Installation order matters:
#    - Install numpy first
#    - Then scipy
#    - Then scikit-learn
#    - Then other packages
# ============================================================================
